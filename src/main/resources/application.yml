spring:
  datasource:
    password: Mama13623717782
    username: nmf
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://rm-uf6d34064973z54jy0o.mysql.rds.aliyuncs.com:3306/todolist_test2?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&useSSL=false
  redis:
    host: 106.15.177.150
    port: 6379
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
  kafka:
    bootstrap-servers: 106.15.177.150:9092, 106.15.177.150:9093
    producer:
      retries: 0
      batch-size: 16384
      buffer-memory: 16384
      acks: 1
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      # 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
      group-id: test
      # smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
      auto-offset-reset: earliest
      # enable.auto.commit:true --> 设置自动提交offset
      enable-auto-commit: true
      #如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
      auto-commit-interval: 5000
      # 指定消息key和消息体的序列化编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer



mybatis:
  configuration:
    map-underscore-to-camel-case: true
  mapper-locations: classpath:mapper/*.xml, classpath:dao/*.xml, classpath:mybatis/mapping/**/*.xml


swagger:
  title: 工程实践
  description: 工程实践接口文档
  license: Apache License, Version 2.0
  license-url: https://www.apache.org/licenses/LICENSE-2.0.html
  base-package: com.todolist_test2.demo
  base-path: /**